{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, read in Guvenen's original data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np; import pandas as pd; import matplotlib.pyplot as plt; import statsmodels.formula.api as sm\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_stata('/Users/tew207/Desktop/RED_ACCEPTED_FINAL_DATA_CODE/ready_newdata.dta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some preliminary defintions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tinit = 67; tlast = 96\n",
    "ageinit = 20; agelast = 64\n",
    "agecell = 4\n",
    "minyrs = 20\n",
    "nlag = 29\n",
    "agelb = 19; ageub = agelb + agecell\n",
    "agemidpt = (agelb+ageub)/2  # = 21\n",
    "agemax = (agelast + agelast - agecell)/2 - (ageub+agelb)/2  # = 41 (maximum age a cohort can reach)\n",
    "oldcoh = agelast - minyrs - ageinit   # number of cohort existing in the first year\n",
    "newcoh = tlast - (minyrs-1) - (tinit+1)  # number of cohorts entering after first year\n",
    "maxcoh = oldcoh + newcoh   # total number of cohorts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some changes to the variables containing information about educational achievement (basically interpolating grades in 1969, 1970, 1971, 1972, 1973 and 1974):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(94,99):\n",
    "    data.rename(columns={\"upedu\"+str(i)+\"h\": \"grade\"+str(i)}, inplace=True)\n",
    "\n",
    "data[\"grade72\"] = data[\"edcn72\"]\n",
    "data.loc[data[\"grade72\"]>25, \"grade72\"] = np.nan # take out values of grade above 25\n",
    "data[\"grade75\"] = data[\"edcn75\"]\n",
    "data.loc[data[\"grade75\"]>25, \"grade75\"] = np.nan\n",
    "\n",
    "data[\"grade69\"] = 0\n",
    "data.loc[(data.seqno68==1) & (data.seqno69==1), \"grade69\"] = data[(data.seqno68==1) & (data.seqno69==1)].grade68\n",
    "cond = (data.seqno72==1) & (data.seqno69==1) & (data.grade69==0)\n",
    "data.loc[cond, \"grade69\"] = data[cond].grade72\n",
    "\n",
    "data.loc[(data.seqno68==1) & (data.seqno70==1), \"grade70\"] = data[(data.seqno68==1) & (data.seqno69==1)].grade68\n",
    "cond = (data.seqno70==1) & (data.seqno72==1) & (data.grade69==0)\n",
    "data.loc[cond, \"grade70\"] = data[cond].grade72\n",
    "\n",
    "data.loc[(data.seqno71==1) & (data.seqno70==1), \"grade71\"] = data[(data.seqno71==1) & (data.seqno70==1)].grade70\n",
    "cond = (data.seqno71==1) & (data.seqno72==1) & (data.grade71==0)\n",
    "data.loc[cond, \"grade71\"] = data[cond].grade72\n",
    "\n",
    "data.loc[(data.seqno73==1) & (data.seqno72==1), \"grade73\"] = data[(data.seqno73==1) & (data.seqno72==1)].grade72\n",
    "cond = (data.grade73==0) & (data.seqno73==1) & (data.seqno75==1)\n",
    "data.loc[cond, \"grade73\"] = data[cond].grade75\n",
    "\n",
    "data.loc[(data.seqno74==1) & (data.seqno72==1), \"grade74\"] = data[(data.seqno74==1) & (data.seqno72==1)].grade72\n",
    "cond = (data.grade74==0) & (data.seqno74==1) & (data.seqno75==1)\n",
    "data.loc[cond, \"grade74\"] = data[cond].grade75\n",
    "\n",
    "for i in range(68, 98):\n",
    "    data.loc[data[\"grade\"+str(i)]>30, \"grade\"+str(i)] = np.nan # take out grades above 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First define a dictionary containing the relative real wages for years 1967 to 1996 (recall that in the PSID, household income refers to the year prior to the survey, i.e. the survey in 1968 asked about income in the year 1967), then replace all with missing all observations which:\n",
    "\n",
    "1. Head real wage less than \\$ 2 or more than \\$ 520 in 1996 prices\n",
    "2. Head hours less than 520 or more than 5096\n",
    "3. Positive hours and no income or positive income and no hours\n",
    "\n",
    "Then, create a college dummy, using the direct measure (`hdedcnXX` are the variables `V313` ff., whose value is 7 or 8 if college was completed) or proxying with more than 15 years of education for post-1990, when the direct measure is not available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "awg = {\"67\":2.85, \"68\":3.02, \"69\":3.22, \"70\":3.40, \"71\":3.63, \"72\":3.90,\n",
    "       \"73\":4.14, \"74\":4.43, \"75\":4.73, \"76\":5.06, \"77\":5.44, \"78\":5.87,\n",
    "       \"79\":6.33, \"80\":6.84, \"81\":7.43, \"82\":7.86, \"83\":8.19, \"84\":8.48,\n",
    "       \"85\":8.73, \"86\":8.92, \"87\":9.13, \"88\":9.43, \"89\":9.80, \"90\":10.19,\n",
    "       \"91\":10.50, \"92\":10.76, \"93\":11.03, \"94\":11.32, \"95\":11.64, \"96\":12.03}\n",
    "\n",
    "for i in range(67,97):\n",
    "    data[\"rawg\"+str(i)] = awg[str(i)]/data[\"prc\"+str(i)]\n",
    "    cond1 = (data[\"rhdwg\"+str(i)] <= 2*data[\"rawg\"+str(i)]/awg[\"96\"]) | (data[\"rhdwg\"+str(i)] > 400*data[\"rawg\"+str(i)]/awg[\"96\"]) \n",
    "    cond2 = (data[\"hwkhrs\"+str(i)] > 5096) | (data[\"hwkhrs\"+str(i)] < 520)\n",
    "    cond3 = (data[\"rhdlbin\"+str(i)] == 0) & (data[\"hwkhrs\"+str(i)] > 0)\n",
    "    cond4 = (data[\"rhdlbin\"+str(i)] > 0) & (data[\"hwkhrs\"+str(i)] == 0)\n",
    "    data.loc[np.logical_or.reduce((cond1, cond2, cond3, cond4)), \"rhdlbin\"+str(i)] = np.nan \n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "Only needed for analysis by education level: generate college dummies\n",
    "\n",
    "for i in range(68,91): # dummy variable coldum68-90, 1 if hdedcnXX is 7 or 8\n",
    "    data[\"coldum\"+str(i)] = 0\n",
    "    data.loc[(data[\"hdedcn\"+str(i)]==7) | (data[\"hdedcn\"+str(i)]==8), \"coldum\"+str(i)] = 1\n",
    "    \n",
    "for i in range(91,98): # dummy variable coldum91-98, 1 if gradeXX is >16\n",
    "    data[\"coldum\"+str(i)] = 0\n",
    "    data.loc[(data[\"grade\"+str(i)] >= 16) & (np.isfinite(data[\"grade\"+str(i)])), \"coldum\"+str(i)] = 1\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, create dummies for:\n",
    "\n",
    "1. Age between 20 and 64 inclusive\n",
    "2. Individual is head\n",
    "2. Sex male\n",
    "3. Labour income positive\n",
    "\n",
    "and record the number of years for which all four dummies are equal to one in a new variable `kept`.\n",
    "Remove all observations with less than `minyrs` years for which all dummies are one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1270 individuals with at least 20 years of valid observations\n"
     ]
    }
   ],
   "source": [
    "data[\"kept\"] = 0\n",
    "\n",
    "for i in range(68,98):\n",
    "    ii = i-1\n",
    "    # Dummy for 19<age<65\n",
    "    data[\"dum_age\"+str(i)] = 0 \n",
    "    data.loc[(data[\"agehd\"+str(i)] >= ageinit) & (data[\"agehd\"+str(i)] <= agelast), \"dum_age\"+str(i)] = 1  \n",
    "    # Dummy for head of household\n",
    "    data[\"dum_seq\"+str(i)] = 0 \n",
    "    data.loc[data[\"seqno\"+str(i)]==1, \"dum_seq\"+str(i)] = 1 \n",
    "    # Dummy for sex of head \n",
    "    data[\"dum_sex\"+str(i)] = 0 \n",
    "    data.loc[data[\"sexhd\"+str(i)]==1 ,\"dum_sex\"+str(i)] = 1  \n",
    "    # Dummy for positive labour income\n",
    "    data[\"dum_lab\"+str(ii)] = 0 \n",
    "    data.loc[data[\"rhdlbin\"+str(ii)]>0, \"dum_lab\"+str(ii)] = 1\n",
    "    # Dummy for agedum*headdum*sexdum*incdum \n",
    "    data.kept += data[\"dum_age\"+str(i)]*data[\"dum_seq\"+str(i)]*data[\"dum_sex\"+str(i)]*data[\"dum_lab\"+str(ii)]\n",
    "    # Generate log income\n",
    "    data[\"logrinc\"+str(ii)] = np.log(data[\"rhdlbin\"+str(ii)])\n",
    "    # Experience is age - education (up to 12 years) - 6 \n",
    "    data[\"edu_capped\"] = data[\"grade\"+str(i)].fillna(0)\n",
    "    data.loc[data[\"edu_capped\"]<12, \"edu_capped\"] = 12\n",
    "    data[\"expr\"+str(i)] = data[\"agehd\"+str(i)] - data[\"edu_capped\"] - 6\n",
    "    \n",
    "print \"There are\", sum(data.kept>=minyrs), \"individuals with at least\", minyrs, \"years of valid observations\"\n",
    "data = data[data.kept>=minyrs]\n",
    "\n",
    "data[\"unidno\"] = range(1,data.shape[0]+1)\n",
    "data[\"k\"] = data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop some variables and rename those variables that might create problems when identifying stub names in wide-to-long conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_drop = [\"educ\", \"edcn\", \"prc\", \"rawg\", \"awg\", \"upedu\", \"_merge\", \"edu_capped\", \"yrdum\"]\n",
    "drop_all = []\n",
    "\n",
    "for d in to_drop:\n",
    "    for colname in data.columns:\n",
    "        if colname[0:len(d)]==d:\n",
    "            drop_all.append(colname)\n",
    "\n",
    "data.drop(drop_all, axis=1, inplace=True)\n",
    "\n",
    "data.rename({\"age\": \"indage\", \"sex\":\"indsex\"}, inplace=True)\n",
    "for i in range(67,100):\n",
    "    try:\n",
    "        data.rename(columns={\"agehd\"+str(i) : \"hdage\"+str(i)}, inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        data.rename(columns={\"hdwg\"+str(i) : \"nhdwg\"+str(i)}, inplace=True)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the data set from wide to long format; create squares, cubes and quadruples of experience, drop observations outside first and last year of analysis and create year dummies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1270 observations below year 67 dropped\n",
      "3810 observations above year 96 dropped\n"
     ]
    }
   ],
   "source": [
    "data_long = pd.wide_to_long(data, ['age', 'hdage', 'dum_age', 'expr', 'hdedcn', 'hdlbin', 'nhdwg', 'rhdwg', 'grade', \n",
    "                                   'hwkhrs', 'id', 'dum_lab', 'rhdlbin', 'logrinc', 'numfam', 'relh', 'dum_seq', \n",
    "                                   'seqno', 'dum_sex', 'sexhd'], i=\"unidno\", j=\"year\")\n",
    "\n",
    "data_long.reset_index(inplace=True)\n",
    "data_long[\"year\"] = data_long.year.astype(int)\n",
    "\n",
    "# create squared, cubed, quadrupled experience variables\n",
    "data_long[\"agehdsq\"] = data_long[\"expr\"]**2/100\n",
    "data_long[\"agehdcu\"] = data_long[\"expr\"]**3/1000\n",
    "data_long[\"agehdqr\"] = data_long[\"expr\"]**4/10000\n",
    "\n",
    "# drop sample outside initial/last year range\n",
    "print sum(data_long.year<=tinit), \"observations below year\", tinit, \"dropped\"\n",
    "print sum(data_long.year>tlast), \"observations above year\", tlast, \"dropped\"\n",
    "data_long = data_long[(data_long.year>tinit)&(data_long.year<=tlast)]\n",
    "\n",
    "# Create year dummies, run regression\n",
    "data = pd.concat([data_long, pd.get_dummies(data_long[\"year\"], prefix=\"yrdum\")], axis=1)\n",
    "result = sm.ols(formula = \"logrinc ~ hdage + agehdsq +\"+\"+\".join([\"yrdum_\"+str(i) for i in range(68,96)]), data=data).fit()\n",
    "data = data[[col for col in data.columns if col[:5] != 'yrdum']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each year from 1968 to 1996, fit the regression:\n",
    "$$\n",
    "y_t = \\beta_0 + \\beta_1 age_t + \\beta_2 expr^2_t + \\beta_3 expr^3_t + \\varepsilon_t\n",
    "$$\n",
    "and record the resulting contants, coefficients and residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newcols = [\"alphaage\", \"alphagesq\", \"alphagecu\", \"alphacons\", \"residual\"]\n",
    "data = pd.concat([data, pd.DataFrame(index=data.index, columns=newcols, dtype=float)], axis=1)\n",
    "\n",
    "for i in range(tinit+1,tlast+1):\n",
    "    cond = (data[\"year\"]==i) & (data.seqno*data.dum_lab*data.dum_age*data.dum_sex==1)\n",
    "    # fit regression\n",
    "    result = sm.ols(\"logrinc ~ hdage + agehdsq + agehdcu\", data=data[cond]).fit()\n",
    "    # save coefficients\n",
    "    data.loc[cond, [\"alphaage\", \"alphagesq\", \"alphagecu\", \"alphacons\"]] = list(result.params)\n",
    "    # save residuals\n",
    "    data.loc[cond, \"residual\"] = result.resid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform time-series operations to create the lag/lead residuals (important: order data by idno, year before shifting columns up to create lagged residuals):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre-allocate columns for speed\n",
    "data[\"combined\"] = data.seqno*data.dum_lab*data.dum_sex*data.dum_age\n",
    "newcols = [\"resid\"+str(i)+\"_\"+str(j) for i in range(1,agemax+1) for j in range(1,tlast-tinit+2)]\n",
    "data = pd.concat([data, pd.DataFrame(index=data.index, columns=newcols, dtype=float)], axis=1)\n",
    "newcols = [\"resid\"+str(i)+\"f\"+str(j) for i in range(1,agemax+1) for j in range(1,tlast-tinit+2)]\n",
    "data = pd.concat([data, pd.DataFrame(index=data.index, columns=newcols, dtype=float)], axis=1)\n",
    "\n",
    "# Sort by id and year, reset index \n",
    "data.sort(columns=[\"unidno\", \"year\"], inplace=True)\n",
    "data.index = range(1, len(data)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the lagged covariance vectors as columns in the dataframe\n",
    "j = ageub  # Cohort age upper bound\n",
    "m = 0      # Cohort age midpoint\n",
    "\n",
    "for i in range(agelb+1,agelast-agecell+1):\n",
    "    j += 1    # Increment upper age bound\n",
    "    m += 1    # Increment age mid-point\n",
    "    n = 0     # Lag counter\n",
    "    t = 0     # Year counter (t=1 is year 1968)\n",
    "    for k in range(tinit+1,tlast+1):\n",
    "        t += 1\n",
    "        cond = (data.combined==1) & (data.hdage.isin(range(i,j+1))) & (data.year==k)\n",
    "        data.loc[cond, \"resid\"+str(m)+\"_\"+str(t)] = data[cond].residual\n",
    "        data.loc[:, \"resid\"+str(m)+\"f\"+str(t)] = data[\"resid\"+str(m)+\"_\"+str(t)].shift(-n)\n",
    "        data.drop(\"resid\"+str(m)+\"_\"+str(t), axis=1, inplace=True)\n",
    "        n += 1    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a `(maxcoh, agemax, agemax)` matrix that holds the autocovariances between residuals at different lags for different cohorts, and a similar sized matrix to record the observations used to calculate those covariances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cov holds the covariances, N the observations used to calculate them\n",
    "Cov = np.full((maxcoh, agemax, agemax), np.nan)\n",
    "N = np.full((maxcoh, agemax, agemax), np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for time in range(1, tlast-tinit+1):\n",
    "    for age in range(1, agemax+1):\n",
    "        c = min(age,time,nlag)\n",
    "        for k in range(1,c+1):\n",
    "            m = c - k\n",
    "            l = age - m\n",
    "            x = time - m\n",
    "            cohort = age - time + newcoh + 1\n",
    "            cond = (~np.isnan(data[\"resid\"+str(age)+\"f\"+str(time)])) & (~np.isnan(data[\"resid\"+str(l)+\"f\"+str(x)]))\n",
    "            obs = len(data[cond])\n",
    "            if (obs>10) & (cohort in range(1, maxcoh+1)):\n",
    "                cov = np.cov(data.loc[cond, \"resid\"+str(age)+\"f\"+str(time)], data.loc[cond, \"resid\"+str(l)+\"f\"+str(x)])\n",
    "                Cov[cohort-1, age-1, l-1] = cov[0,1]\n",
    "                N[cohort-1, age-1, l-1] = obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, export the covariances and observations as a `hdf5` file to be read in by the optimization routine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "output = h5py.File('output.h5', 'w')\n",
    "output.create_dataset('Covariances', data=Cov)\n",
    "output.create_dataset('Observations', data=N)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
